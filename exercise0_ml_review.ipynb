{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 525 exercise 0:  a review of machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These questions are based on material covered in CS 345.  For your reference, here's a link to the [github repository](https://github.com/asabenhur/CS345/blob/master/fall24) that contains the course materials.  Links to specific relevant notebooks are provided in the coding section of the assignment.\n",
    "\n",
    "### Short questions\n",
    "\n",
    "1. What are hyperparameters and why is it important to find good values for them?  How is optimizing hyperparameters different than optimizing the value of classifier parameters such as the weight vector of a linear classifier?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters are parameters that influence your model, but cannot be directly solved for. This makes them difficult to identify, and can greatly influence the success of a classifier. standard parameters such as wieght vectors can be optimized to find the best solution for your data. hyperparameters do not have a objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Give an example of a machine learning algorithm and hyperparameter values where you expect to see a large gap between its accuracy on the training set and test set (assuming a challenging enough dataset so that it does not perform perfectly on the test set).  Explain why you expect to see that behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Is the following statement true or false?  Explain!  Taking a small step in the direction of the gradient of a function will lead towards a local or global minimum of the function you are trying to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In machine learning it is important to compare the accuracy of your classifier to a simple baseline.  List multiple reasons why that is the case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding questions\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Plot the accuracy of random forests as a function of the number of trees that are used in the ensemble (accessed in scikit-learn using the `n_estimators` attribute).  Use the Leukemia dataset described below.  In your plot, compute accuracy using ten-fold cross-validation.\n",
    "Choose a wide enough range of values for the number of trees that illustrates the behavior as a function of this hyperparameter.  Is overfitting observed at any point in your plot?  Explain!  In your code do not use the scikit-learn `validation_curve` function.\n",
    "\n",
    "For your reference, here's the notebook I used for presenting the topic of [random forests](https://github.com/asabenhur/CS345/blob/master/fall24/notebooks/module06_02_ensemble_methods.ipynb) in CS 345.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Leukemia gene expression dataset**\n",
    "\n",
    "This dataset looks at biological samples taken from leukemia patients with two types of leukemia: acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) and measures the expression of over 7,000 genes using DNA microarrays.  The technology of DNA microarrays as a way of probing gene expression has since been replaced by next generation sequencing, which will be covered later in the course.  However, the analysis opportunities remain similar.  The data was taken from the following publication:\n",
    "\n",
    "> Golub, Todd R., et al. \"Molecular classification of cancer: class discovery and class prediction by gene expression monitoring.\" Science  (1999): 531-537.\n",
    "\n",
    "Here's code for creating the feature matrix and label vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 7128), (72,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# if you don't have requests installed you can use urlopen which is part\n",
    "# of the python standard library\n",
    "# from urllib.request import urlopen\n",
    "link = \"https://web.stanford.edu/~hastie/CASI_files/DATA/leukemia_big.csv\"\n",
    "# retrieve the contents of the file\n",
    "contents = requests.get(link)\n",
    "lines = contents.text.split()\n",
    "# the data is in csv format and the labels appear in the first \n",
    "# row of the dataset:\n",
    "class_convert = {'ALL':1, 'AML':0}\n",
    "y = np.array([class_convert[token] for token in lines[0].split(',')])\n",
    "X = np.array([ [float(token) for token in line.split(',')] \n",
    "              for line in lines[1:] ])\n",
    "X = X.transpose()\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute the accuracy of a non-linear SVM with Gaussian kernel on the Leukemia dataset using ten-fold cross-validation with optimal hyperparameters chosen using nested cross-validation.\n",
    "In your analysis perform model selection over the value of the soft-margin constant and the width parameter of the Gaussian kernel.  For each hyperparameter choose a wide enough range of values that makes sense.  \n",
    "Compare the performance of the non-linear SVM to that of a linear SVM where you select an optimal value of the soft-margin constant, again using nested cross-validation.  Hint:  It is possible to get similar performance using the non-linear SVM.\n",
    "\n",
    "Here are links to some of the notebooks from CS 345 where I presented SVMs and model selection:\n",
    "\n",
    "*  Linear SVMs ([notebook](https://github.com/asabenhur/CS345/blob/master/fall24/notebooks/module02_04_svm.ipynb))\n",
    "*  Non-linear SVMs and kernels ([notebook](https://github.com/asabenhur/CS345/blob/master/fall24/notebooks/module04_03_kernels.ipynb))\n",
    "*  Model selection using a validation set ([notebook](https://github.com/asabenhur/CS345/blob/master/fall24/notebooks/module05_01_hyperparameters_validation_set.ipynb))\n",
    "*  Model selection using nested cross-validation ([notebook](https://github.com/asabenhur/CS345/blob/master/fall24/notebooks/module05_03_model_selection.ipynb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
